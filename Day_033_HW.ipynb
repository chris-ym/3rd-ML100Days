{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習時間"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "請觀看李宏毅教授以神奇寶貝進化 CP 值預測的範例，解說何謂機器學習與過擬合。並回答以下問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[youtube](https://www.youtube.com/watch?v=fegAeph9UaA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 模型的泛化能力 (generalization) 是指什麼？\n",
    "在任何data之中是否都能有良好的預測，不單單只是training data上表現良好，更重要的是要關注testing data是否過擬合(overfitting)的問題，進而達到最佳的預測表現\n",
    "\n",
    "### 2. 分類問題與回歸問題分別可用的目標函數有哪些？\n",
    "參考網址:1.https://www.twblogs.net/a/5c188f10bd9eee5e41847a50\n",
    "        2.https://buzzorange.com/techorange/2018/06/22/computer-learning-5-tips/\n",
    "        \n",
    "        \n",
    "#### 1.分類問題:\n",
    "\n",
    "(1)平均絕對誤差(MAE)(L1損失函數)\n",
    "\n",
    "(2)均方誤差(MSE)(L2損失函數)\n",
    "\n",
    "(3)Huber損失函數(smooth mean absolute error) : Huber損失函數克服了MAE和MSE的缺點，不僅可以保持損失函數具有連續的導數，同時可以利用MSE梯度隨誤差減小的特性來得到更精確的最小值\n",
    "\n",
    "(4)Log-Cosh損失函數\n",
    "\n",
    "(5)分位數損失函數(QUANTILE) : 如何選取合適的分位值取決於我們對正誤差和反誤差的重視程度。損失函數通過分位值（γ）對高估和低估給予不同的懲罰。例如，當分位數損失函數 γ=0.25 時，對高估的懲罰更大，使得預測值略低於中值。\n",
    "\n",
    "\n",
    "#### 2.回歸問題:\n",
    "\n",
    "(1)0-1損失函數:以二分類問題為例\n",
    "\n",
    "(2)交叉熵損失函數（Logistic迴歸）\n",
    "\n",
    "(3)指數損失函數\n",
    "\n",
    "(4)對比損失函數\n",
    "\n",
    "(5)資訊增益\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
